{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeRF: Neural Radiance Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nerf.infer\n",
    "import nerf.train\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.jit as jit\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from nerf.data import BlenderDataset\n",
    "from nerf.core import NeRF\n",
    "from nerf.core import BoundedVolumeRaymarcher as BVR\n",
    "from nerfcfg import RenderConfig, TrainConfig\n",
    "from PIL import Image\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666f19b0e8d54c1e83ce8593b923c6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(GridspecLayout(children=(Dropdown(description='Scene', index=3, layout=Layout(grid_area='widget0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tcfg = TrainConfig()\n",
    "tcfg.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9614/2270064504.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlenderDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# val = BlenderDataset(tcfg.blender, tcfg.scene, \"val\", step=tcfg.step, scale=tcfg.step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# test = BlenderDataset(tcfg.blender, tcfg.scene, \"test\", step=tcfg.step, scale=tcfg.step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/NeRF/nerf/data/blender.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, scene, split, step, scale)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'function'"
     ]
    }
   ],
   "source": [
    "train = BlenderDataset(tcfg.blender, tcfg.scene, \"train\", step=tcfg.step, scale=tcfg.step)\n",
    "# val = BlenderDataset(tcfg.blender, tcfg.scene, \"val\", step=tcfg.step, scale=tcfg.step)\n",
    "# test = BlenderDataset(tcfg.blender, tcfg.scene, \"test\", step=tcfg.step, scale=tcfg.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, H = train.W, train.H\n",
    "C, vro, vrd = train.C[:W * H], train.ro[:W * H], train.rd[:W * H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = C.view(W, H, 3).clip(0, 1) * 255\n",
    "gt = gt.numpy().astype(np.uint8)\n",
    "\n",
    "img = Image.fromarray(gt)\n",
    "img.save(tcfg.gt_png)\n",
    "display(img.resize((256, 256)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, sigma = (tcfg.features, tcfg.features), (tcfg.sigma, tcfg.sigma)\n",
    "nerf = NeRF(*features, *sigma, width=tcfg.width, depth=tcfg.depth).cuda()\n",
    "raymarcher = BVR(tcfg.tn, tcfg.tf, samples=tcfg.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MSELoss().cuda()\n",
    "optim = Adam(nerf.parameters(), lr=tcfg.lr)\n",
    "scaler = GradScaler(enabled=tcfg.fp16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gt = widgets.Image(value=b\"\", format=\"png\", width=256, height=256)\n",
    "w_pred = widgets.Image(value=b\"\", format=\"png\", width=256, height=256)\n",
    "\n",
    "with open(tcfg.gt_png, \"rb\") as f:\n",
    "    w_gt.value = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_callback = lambda e: (e % (tcfg.log - 1) == 0) or (e == (tcfg.epochs - 1))\n",
    "\n",
    "\n",
    "def save_callback(epoch: int) -> None:\n",
    "    if do_callback(epoch):\n",
    "        print(f\"[NeRF] Saving Model's Weights to `{tcfg.model_ts}`\")\n",
    "        jit.save(jit.script(nerf), tcfg.model_ts)\n",
    "\n",
    "        \n",
    "def render_callback(epoch: int) -> None:\n",
    "    if do_callback(epoch):\n",
    "        pred = nerf.infer(raymarcher, vro, vrd, W, H, batch_size=tcfg.batch_size)\n",
    "        pred = pred.numpy().astype(np.uint8)\n",
    "        \n",
    "        img = Image.fromarray(pred)\n",
    "        img.save(tcfg.pred_png)\n",
    "      \n",
    "    \n",
    "def update_pred(epoch: int) -> None:\n",
    "    if do_callback(epoch):\n",
    "        with open(tcfg.pred_png, \"rb\") as f:\n",
    "            w_pred.value = f.read()\n",
    "\n",
    "            \n",
    "callbacks = [save_callback, render_callback, update_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(widgets.HBox([w_gt, w_pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = nerf.fit(\n",
    "    raymarcher,\n",
    "    optim,\n",
    "    criterion,\n",
    "    scaler,\n",
    "    train,\n",
    "    epochs=tcfg.epochs,\n",
    "    batch_size=tcfg.batch_size,\n",
    "    jobs=tcfg.jobs,\n",
    "    perturb=tcfg.perturb,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(len(history.train)))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Train History\")\n",
    "plt.subplots(1, 2, 1)\n",
    "plt.gca().set_title(\"MSE\")\n",
    "plt.plot(x=x, y=[mse for mse, _ in history.train], label=\"train\")\n",
    "plt.plot(x=x, y=[mse for mse, _ in history.val], label=\"val\")\n",
    "plt.subplots(1, 2, 2)\n",
    "plt.gca().set_title(\"PSNR\")\n",
    "plt.plot(x=x, y=[psnr for _, psnr in history.train], label=\"train\")\n",
    "plt.plot(x=x, y=[psnr for _, psnr in history.val], label=\"val\")\n",
    "\n",
    "print(f\"Test MSE={history.test[0]} PSNR={history.test[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcfg = RenderConfig()\n",
    "rcfg.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = BlenderDataset(rcfg.blender, rcfg.scene, \"val\", step=rcfg.step, scale=rcfg.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = -1 / 6 * np.pi, -1 / 6 * np.pi\n",
    "phi = -np.pi, np.pi\n",
    "radius = 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros, rds = val.turnaround_data(theta=theta, phi=phi, radius=radius, samples=rcfg.frames)\n",
    "W, H = val.W, val.H\n",
    "S = W * H\n",
    "n = len(ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerf = jit.load(rcfg.model_ts).cuda()\n",
    "raymarcher = BVR(rcfg.tn, rcfg.tf, samples=rcfg.samples)\n",
    "\n",
    "nerf.infer = lambda *args, **kwargs: NeRF.infer(nerf, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = np.zeros((rcfg.frames, W, H, 3), dtype=np.uint8)\n",
    "pbar = tqdm(range(0, n, S), desc=\"[NeRF] Frame\")\n",
    "for i, s in enumerate(pbar):\n",
    "    ro, rd = ros[s:s + S], rds[s:s + S]\n",
    "    pred = nerf.infer(raymarcher, ro, rd, W, H, batch_size=rcfg.batch_size, verbose=True)\n",
    "    preds[i] = pred.numpy().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = ImageSequenceClip(list(preds), durations=[1. / rcfg.fps] * rcfg.frames)\n",
    "clip.write_gif(rcfg.pred_gif, fps=rcfg.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gif = widgets.Image(value=b\"\", format=\"gif\", width=256, height=256)\n",
    "\n",
    "with open(rcfg.pred_gif, \"rb\") as f:\n",
    "    w_gif.value = f.read()\n",
    "    \n",
    "display(w_gif)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
